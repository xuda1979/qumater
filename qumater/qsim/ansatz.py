"""Variational ansÃ¤tze inspired by hardware-agnostic quantum compilation."""
from __future__ import annotations

from dataclasses import dataclass
from typing import Iterable, Sequence

import numpy as np


def _rotation_y(theta: float) -> np.ndarray:
    c = np.cos(theta / 2.0)
    s = np.sin(theta / 2.0)
    return np.array([[c, -s], [s, c]], dtype=complex)


def _rotation_z(theta: float) -> np.ndarray:
    return np.array(
        [[np.exp(-1j * theta / 2.0), 0.0], [0.0, np.exp(1j * theta / 2.0)]],
        dtype=complex,
    )


def _apply_single_qubit_gate(state: np.ndarray, gate: np.ndarray, qubit: int, num_qubits: int) -> np.ndarray:
    state_t = state.reshape([2] * num_qubits)
    state_t = np.moveaxis(state_t, qubit, 0)
    state_t = np.tensordot(gate, state_t, axes=[1, 0])
    state_t = np.moveaxis(state_t, 0, qubit)
    return state_t.reshape(-1)


def _apply_cz(state: np.ndarray, control: int, target: int, num_qubits: int) -> np.ndarray:
    if control == target:
        raise ValueError("Control and target qubits must be distinct")
    shape = [2] * num_qubits
    state_t = state.reshape(shape)
    slicer = [slice(None)] * num_qubits
    slicer[control] = 1
    slicer[target] = 1
    state_t[tuple(slicer)] *= -1.0
    return state_t.reshape(-1)


@dataclass
class HardwareAgnosticAnsatz:
    """Hardware-agnostic low-depth ansatz.

    The Tencent report highlights Phasecraft's *hardware-agnostic* circuits that
    can be compiled onto different quantum backends with minimal depth
    inflation.  We emulate this concept by alternating layers of parameterised
    single qubit rotations with sparse entangling gates arranged in a ring.  The
    ansatz keeps gate counts modest yet expressive enough for strongly
    correlated benchmarks such as the 2x2 Fermi-Hubbard model referenced in the
    article.
    """

    num_qubits: int
    layers: int = 1

    def __post_init__(self) -> None:
        if self.num_qubits < 1:
            raise ValueError("num_qubits must be positive")
        if self.layers < 1:
            raise ValueError("layers must be positive")

    @property
    def parameter_count(self) -> int:
        """Return the number of continuous parameters required by the ansatz."""

        return self.num_qubits * self.layers * 2

    def prepare_state(self, parameters: Sequence[float]) -> np.ndarray:
        """Return the state vector generated by the ansatz.

        Parameters
        ----------
        parameters:
            Sequence of rotation angles.  Two angles per qubit per layer are
            expected (``RY`` and ``RZ`` rotations respectively).
        """

        parameters = list(parameters)
        if len(parameters) != self.parameter_count:
            raise ValueError(
                f"Expected {self.parameter_count} parameters, received {len(parameters)}"
            )

        state = np.zeros(2**self.num_qubits, dtype=complex)
        state[0] = 1.0

        index = 0
        for _ in range(self.layers):
            for qubit in range(self.num_qubits):
                theta = parameters[index]
                phi = parameters[index + 1]
                index += 2
                state = _apply_single_qubit_gate(state, _rotation_y(theta), qubit, self.num_qubits)
                state = _apply_single_qubit_gate(state, _rotation_z(phi), qubit, self.num_qubits)

            for qubit in range(self.num_qubits):
                target = (qubit + 1) % self.num_qubits
                if target == qubit:
                    continue
                state = _apply_cz(state, qubit, target, self.num_qubits)

        norm = np.linalg.norm(state)
        if norm == 0:
            raise RuntimeError("Ansatz produced the zero vector")
        return state / norm

    def parameter_gradient(self, parameters: Sequence[float]) -> np.ndarray:
        """Finite-difference gradient of the prepared state's amplitudes.

        Variational quantum compiling stacks frequently rely on efficient
        gradient evaluation to keep optimisation stable on NISQ era hardware.
        We expose gradients to support meta-optimisers and benchmarking.
        """

        parameters = np.asarray(parameters, dtype=float)
        eps = 1e-6
        base_state = self.prepare_state(parameters)
        grads = np.zeros((self.parameter_count, base_state.size), dtype=complex)
        for i in range(self.parameter_count):
            shifted = parameters.copy()
            shifted[i] += eps
            grads[i] = (self.prepare_state(shifted) - base_state) / eps
        return grads


__all__ = ["HardwareAgnosticAnsatz"]
